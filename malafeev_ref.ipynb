{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Malafeev CNN reference method\n",
    "\n",
    "Malafeev, A., Hertig-Godeschalk, A., Schreier, D. R., Skorucak, J., Mathis, J., & Achermann, P. (2021). Automatic Detection of Microsleep Episodes With Deep Learning. Frontiers in Neuroscience, 15, 564098. https://doi.org/10.3389/fnins.2021.564098\n",
    "\n",
    "This is a reference method with slightly modified implemenations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3200, 1, 3)]      0         \n",
      "                                                                 \n",
      " model (Functional)          (None, 256)               1270528   \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               65792     \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,338,882\n",
      "Trainable params: 1,333,570\n",
      "Non-trainable params: 5,312\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build 16-CNN Model\n",
    "\n",
    "import os\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.callbacks import History \n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Layer,Dense, Dropout, Input, Activation, TimeDistributed, Reshape\n",
    "from keras.layers import  GRU, Bidirectional\n",
    "from keras.layers import  Conv1D, Conv2D, MaxPooling2D, Flatten, BatchNormalization, LSTM, ZeroPadding2D, GlobalAveragePooling2D, SpatialDropout2D\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "def build_model(data_dim, n_channels, n_cl):\n",
    "\teeg_channels = 1\n",
    "\tact_conv = 'relu'\n",
    "\tinit_conv = 'glorot_normal'\n",
    "\tdp_conv = 0.3\n",
    "\tdef cnn_block(input_shape):\n",
    "\t\tinput = Input(shape=input_shape)\n",
    "\t\tx = GaussianNoise(0.0005)(input)\n",
    "\t\tx = Conv2D(32, (3, 1), strides=(1, 1), padding='same', kernel_initializer=init_conv)(x)\n",
    "\t\tx = BatchNormalization()(x)\n",
    "\t\tx = Activation(act_conv)(x)\n",
    "\t\tx = MaxPooling2D(pool_size=(2, 1), padding='same')(x)\n",
    "\t\t\n",
    "\t\t\n",
    "\t\tx = Conv2D(64, (3, 1), strides=(1, 1), padding='same', kernel_initializer=init_conv)(x)\n",
    "\t\tx = BatchNormalization()(x)\n",
    "\t\tx = Activation(act_conv)(x)\n",
    "\t\tx = MaxPooling2D(pool_size=(2, 1), padding='same')(x)\n",
    "\t\tfor i in range(4):\n",
    "\t\t\tx = Conv2D(128, (3, 1), strides=(1, 1), padding='same', kernel_initializer=init_conv)(x)\n",
    "\t\t\tx = BatchNormalization()(x)\n",
    "\t\t\tx = Activation(act_conv)(x)\n",
    "\t\t\tx = MaxPooling2D(pool_size=(2, 1), padding='same')(x)\n",
    "\t\tfor i in range(6):\n",
    "\t\t\tx = Conv2D(256, (3, 1), strides=(1, 1), padding='same', kernel_initializer=init_conv)(x)\n",
    "\t\t\tx = BatchNormalization()(x)\n",
    "\t\t\tx = Activation(act_conv)(x)\n",
    "\t\t\tx = MaxPooling2D(pool_size=(2, 1), padding='same')(x)\n",
    "\t\tflatten1 = Flatten()(x)\n",
    "\t\tcnn_eeg = Model(inputs=input, outputs=flatten1)\n",
    "\t\treturn cnn_eeg\n",
    "\t\t\n",
    "\thidden_units1  = 256\n",
    "\tdp_dense = 0.5\n",
    "\n",
    "\teeg_channels = 1\n",
    "\teog_channels = 2\n",
    "\n",
    "\tinput_eeg = Input(shape=( data_dim, 1,  3))\n",
    "\tcnn_eeg = cnn_block(( data_dim, 1, 3))\n",
    "\tx_eeg = cnn_eeg(input_eeg)\n",
    "\tx = BatchNormalization()(x_eeg)\n",
    "\tx = Dropout(dp_dense)(x)\n",
    "\tx =  Dense(units=hidden_units1, activation=act_conv, kernel_initializer=init_conv)(x)\n",
    "\tx = BatchNormalization()(x)\n",
    "\tx = Dropout(dp_dense)(x)\n",
    "\n",
    "\tpredictions = Dense(units=n_cl, activation='softmax', kernel_initializer=init_conv)(x)\n",
    "\n",
    "\tmodel = Model(inputs=[input_eeg] , outputs=[predictions])\n",
    "\treturn [cnn_eeg, model]\n",
    "\n",
    "cnn, model = build_model(3200, 3, 2)\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load some random subjects from train splits\n",
    "with open(\"./splits/skorucack_splits.json\") as f:\n",
    "    splits = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "class MalafeevStudy(object):\n",
    "\n",
    "    fs = 200\n",
    "    win_len = int(16 * fs)\n",
    "    pad_len = int(win_len / 2)\n",
    "\n",
    "    def __init__(self, signal_file, target_file):\n",
    "        \n",
    "        tmp = loadmat(signal_file, struct_as_record=False, squeeze_me=True)\n",
    "        \n",
    "        pre_process = lambda x: np.clip(x / 100, -1, 1)\n",
    "        padding = lambda x: np.pad(x, pad_width=(self.pad_len, self.pad_len), mode=\"constant\", constant_values = (0, 0))\n",
    "\n",
    "        self.E1 = np.expand_dims(padding(pre_process(tmp['Data'].E1)),-1)\n",
    "        self.E2 = np.expand_dims(padding(pre_process(tmp['Data'].E2)), -1)\n",
    "        O1 = np.expand_dims(padding(pre_process(tmp['Data'].eeg_O1)), -1)\n",
    "        O2 = np.expand_dims(padding(pre_process(tmp['Data'].eeg_O2)), -1)\n",
    "        self.EEG = [O1, O2]\n",
    "\n",
    "        targets = loadmat(target_file)['x']\n",
    "        targets[targets!=1] = 0\n",
    "        self.y = to_categorical(targets, num_classes=2) \n",
    "\n",
    "        self.num_win = len(self.y)\n",
    "\n",
    "\n",
    "    def get_window_by_idx(self, i, c):\n",
    "        \n",
    "        \n",
    "        start = int(i*self.fs)\n",
    "        end = int(start+self.win_len)\n",
    "\n",
    "        x = np.concatenate([self.E1[start:end], self.E2[start:end], self.EEG[c][start:end]],axis=1)\n",
    "        x = np.expand_dims(x, -2)\n",
    "\n",
    "        y = self.y[i]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def get_sample_idx(self, study_idx):\n",
    "\n",
    "        sample_idx = np.empty([self.num_win * 2, 3], dtype=int)\n",
    "        for c in range(2):\n",
    "            for i in range(self.num_win):\n",
    "                ix=int(c*self.num_win+i)\n",
    "                sample_idx[ix,...]=(study_idx, i, c)\n",
    "        return sample_idx  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "class Generator(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, split, batch_size):\n",
    "        self.studies = [MalafeevStudy(signal_file=f\"Matlab/data/{f}\", target_file=f\"edf_data/{f.replace('.mat','_new.mat')}\") for f in split]\n",
    "        self.indices = flatten([tmp.get_sample_idx(i) for i, tmp in enumerate(self.studies)])\n",
    "        self.batch_size = batch_size\n",
    "        np.random.shuffle(self.indices)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.indices) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        batch_x = np.empty([self.batch_size, self.studies[0].win_len, 1, 3])\n",
    "        batch_y = np.empty([self.batch_size, 2])\n",
    "\n",
    "        idxs = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        for i, idx in enumerate(idxs):\n",
    "            x, y = self.get_study_windows_by_idx(idx)\n",
    "            batch_x[i,...] = x\n",
    "            batch_y[i,...] = y\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def get_study_windows_by_idx(self, index):\n",
    "\n",
    "        return self.studies[index[0]].get_window_by_idx(index[1], index[2])\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.indices)\n",
    "\n",
    "train_data = Generator(split=splits['train'], batch_size=200)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend\n",
    "\n",
    "fs = 200\n",
    "win_sec = 16\n",
    "win_len = win_sec * fs\n",
    "n_classes = 2\n",
    "n_channels = 3\n",
    "\n",
    "\n",
    "_, model = build_model(win_len, n_channels, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "# Compute class weights\n",
    "y = flatten([x.y[...,1] for x in train_data.studies])\n",
    "cls = np.arange(n_classes)\n",
    "clw = compute_class_weight(class_weight=\"balanced\", classes=cls, y=y)\n",
    "class_weights = {0: clw[0], 1: clw[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "train_model = False\n",
    "folder = \"malafeev42_new\"\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "\n",
    "\n",
    "weight_file = os.path.join(folder,\"CNN_weights.h5\")\n",
    "history_file = os.path.join(folder, \"history\")\n",
    "\n",
    "\n",
    "\n",
    "if train_model:\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Nadam(learning_rate=0.002),\n",
    "                loss=keras.losses.CategoricalCrossentropy(),\n",
    "                metrics=keras.metrics.CategoricalAccuracy())\n",
    "\n",
    "\n",
    "    with tf.device(\"/device:GPU:0\"):\n",
    "        history = model.fit(train_data, \n",
    "                            class_weight=class_weights,\n",
    "                            epochs=3)\n",
    "    \n",
    "    import pickle\n",
    "    model.save_weights(weight_file)\n",
    "\n",
    "    with open(history_file, 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)\n",
    "\n",
    "else:\n",
    "    model.load_weights(weight_file)\n",
    "    model.trainable = False\n",
    "\n",
    "    with open(history_file, 'rb') as file_pi:\n",
    "        history = pickle.load(file_pi)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_study(mdl, study: MalafeevStudy):\n",
    "\n",
    "    n_classes = mdl.output_shape[-1]\n",
    "    n_channels = mdl.input_shape[-1]\n",
    "\n",
    "    ch_x = np.empty([study.num_win, study.win_len, 1, n_channels])\n",
    "    ch_y = np.empty([study.num_win])\n",
    "    study_preds = np.empty([study.num_win, n_classes, n_channels])\n",
    "\n",
    "    idxs = study.get_sample_idx(0)\n",
    "\n",
    "    for ch in range(n_channels):\n",
    "        \n",
    "        ch_idx = idxs[np.where(idxs[:,2]==ch)[0],1:3]\n",
    "        \n",
    "        for i, idx in enumerate(ch_idx):\n",
    "            x, y = study.get_window_by_idx(*idx)\n",
    "            ch_x[i,...] = x\n",
    "            ch_y[i,...] = y[-1]\n",
    "\n",
    "        study_preds[...,ch] = mdl.predict_on_batch(ch_x)\n",
    "\n",
    "    return np.mean(study_preds, axis=2), ch_y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting study: 0pai\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_3/model_2/batch_normalization_14/FusedBatchNormV3' defined at (most recent call last):\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\traitlets\\config\\application.py\", line 985, in launch_instance\n      app.start()\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\SIOS\\AppData\\Local\\Temp\\ipykernel_12580\\2164236807.py\", line 13, in <module>\n      study_prob, study_y = predict_study(model, study)\n    File \"C:\\Users\\SIOS\\AppData\\Local\\Temp\\ipykernel_12580\\1204788849.py\", line 21, in predict_study\n      study_preds[...,ch] = mdl.predict_on_batch(ch_x)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\engine\\training.py\", line 2474, in predict_on_batch\n      outputs = self.predict_function(iterator)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step\n      outputs = model.predict_step(data)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n      return self(x, training=False)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 850, in call\n      outputs = self._fused_batch_norm(inputs, training=training)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 660, in _fused_batch_norm\n      output, mean, variance = control_flow_util.smart_cond(\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 108, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 649, in _fused_batch_norm_inference\n      return tf.compat.v1.nn.fused_batch_norm(\nNode: 'model_3/model_2/batch_normalization_14/FusedBatchNormV3'\nOOM when allocating tensor with shape[2400,32,3200,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_3/model_2/batch_normalization_14/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_2870]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m y_file \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39medf_data/\u001b[39m\u001b[39m{\u001b[39;00mfi\u001b[39m}\u001b[39;00m\u001b[39m_new.mat\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m study \u001b[39m=\u001b[39m MalafeevStudy(signal_file\u001b[39m=\u001b[39msig_file, target_file\u001b[39m=\u001b[39my_file)\n\u001b[1;32m---> 13\u001b[0m study_prob, study_y \u001b[39m=\u001b[39m predict_study(model, study)\n\u001b[0;32m     14\u001b[0m y_pred\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39margmax(study_prob, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m     15\u001b[0m y_true\u001b[39m.\u001b[39mappend(study_y)\n",
      "Cell \u001b[1;32mIn[8], line 21\u001b[0m, in \u001b[0;36mpredict_study\u001b[1;34m(mdl, study)\u001b[0m\n\u001b[0;32m     18\u001b[0m         ch_x[i,\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m] \u001b[39m=\u001b[39m x\n\u001b[0;32m     19\u001b[0m         ch_y[i,\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m] \u001b[39m=\u001b[39m y[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m---> 21\u001b[0m     study_preds[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,ch] \u001b[39m=\u001b[39m mdl\u001b[39m.\u001b[39;49mpredict_on_batch(ch_x)\n\u001b[0;32m     23\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmean(study_preds, axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m), ch_y\n",
      "File \u001b[1;32mc:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\engine\\training.py:2474\u001b[0m, in \u001b[0;36mModel.predict_on_batch\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   2470\u001b[0m     iterator \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39msingle_batch_iterator(\n\u001b[0;32m   2471\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy, x\n\u001b[0;32m   2472\u001b[0m     )\n\u001b[0;32m   2473\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_predict_function()\n\u001b[1;32m-> 2474\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_function(iterator)\n\u001b[0;32m   2475\u001b[0m \u001b[39mreturn\u001b[39;00m tf_utils\u001b[39m.\u001b[39msync_to_numpy_or_python_type(outputs)\n",
      "File \u001b[1;32mc:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model_3/model_2/batch_normalization_14/FusedBatchNormV3' defined at (most recent call last):\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\traitlets\\config\\application.py\", line 985, in launch_instance\n      app.start()\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\SIOS\\AppData\\Local\\Temp\\ipykernel_12580\\2164236807.py\", line 13, in <module>\n      study_prob, study_y = predict_study(model, study)\n    File \"C:\\Users\\SIOS\\AppData\\Local\\Temp\\ipykernel_12580\\1204788849.py\", line 21, in predict_study\n      study_preds[...,ch] = mdl.predict_on_batch(ch_x)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\engine\\training.py\", line 2474, in predict_on_batch\n      outputs = self.predict_function(iterator)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step\n      outputs = model.predict_step(data)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n      return self(x, training=False)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 850, in call\n      outputs = self._fused_batch_norm(inputs, training=training)\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 660, in _fused_batch_norm\n      output, mean, variance = control_flow_util.smart_cond(\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 108, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"c:\\Users\\SIOS\\Anaconda3\\envs\\u-sleep\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 649, in _fused_batch_norm_inference\n      return tf.compat.v1.nn.fused_batch_norm(\nNode: 'model_3/model_2/batch_normalization_14/FusedBatchNormV3'\nOOM when allocating tensor with shape[2400,32,3200,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_3/model_2/batch_normalization_14/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_2870]"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "ids = []\n",
    "\n",
    "for fi in splits['test']:\n",
    "    print(f\"Predicting study: {fi}\")\n",
    "    ids.append(fi)\n",
    "\n",
    "    sig_file = f\"Matlab/data/{fi}.mat\"\n",
    "    y_file = f\"edf_data/{fi}_new.mat\"\n",
    "    study = MalafeevStudy(signal_file=sig_file, target_file=y_file)\n",
    "\n",
    "    study_prob, study_y = predict_study(model, study)\n",
    "    y_pred.append(np.argmax(study_prob, axis=1))\n",
    "    y_true.append(study_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:\t\t0.63\n",
      "Precision:\t0.88\n",
      "F1-Score:\t0.73\n",
      "Cohen's kappa:\t0.71\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score, cohen_kappa_score, confusion_matrix\n",
    "\n",
    "y_true=[(y==1)*1 for y in y_true]\n",
    "y_hat = np.concatenate(y_pred)\n",
    "y = np.concatenate(y_true)==1\n",
    "\n",
    "recall = recall_score(y, y_hat)\n",
    "precision = precision_score(y, y_hat)\n",
    "f1 = f1_score(y, y_hat)\n",
    "kappa = cohen_kappa_score(y, y_hat)\n",
    "\n",
    "print(f\"Recall:\\t\\t{recall:.2f}\")\n",
    "print(f\"Precision:\\t{precision:.2f}\")\n",
    "print(f\"F1-Score:\\t{f1:.2f}\")\n",
    "print(f\"Cohen's kappa:\\t{kappa:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sindri\\anaconda3\\envs\\u-sleep\\lib\\site-packages\\scipy\\io\\matlab\\_mio5.py:493: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  narr = np.asanyarray(source)\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import savemat\n",
    "\n",
    "ids = splits['test']\n",
    "out = {\"id\": ids,\n",
    "    \"yHat\": y_pred,\n",
    "    \"yTrue\": y_true}\n",
    "\n",
    "savemat(\"Matlab/malafeev42_new.mat\", mdict=out)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate train data to check overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting study: AXbm\n",
      "Predicting study: hT38\n",
      "Predicting study: Msy4\n",
      "Predicting study: pPpj\n",
      "Predicting study: go56\n",
      "Predicting study: SOZ3\n",
      "Predicting study: X7s0\n",
      "Predicting study: muls\n",
      "Predicting study: 5bSg\n",
      "Predicting study: Nzhl\n",
      "Predicting study: C1Wu\n",
      "Predicting study: cblr\n",
      "Predicting study: svlu\n",
      "Predicting study: YHLr\n",
      "Predicting study: EHED\n",
      "Predicting study: G7PJ\n",
      "Predicting study: DYYI\n",
      "Predicting study: RfL0\n",
      "Predicting study: ZYFG\n",
      "Predicting study: 0ncr\n",
      "Predicting study: iSqw\n",
      "Predicting study: Dr51\n",
      "Predicting study: UwK6\n",
      "Predicting study: Ivfn\n",
      "Predicting study: LR2s\n",
      "Predicting study: Zpwh\n",
      "Predicting study: DjrT\n",
      "Predicting study: bkx9\n",
      "Predicting study: MS6u\n",
      "Predicting study: fNe4\n",
      "Predicting study: 9098\n",
      "Predicting study: EMcQ\n",
      "Predicting study: YOh8\n",
      "Predicting study: UsSz\n",
      "Predicting study: y5We\n",
      "Predicting study: 9JQY\n",
      "Predicting study: zaca\n",
      "Predicting study: 3J4W\n",
      "Predicting study: sNMf\n",
      "Predicting study: d3ET\n",
      "Predicting study: JCpz\n",
      "Predicting study: oOMR\n",
      "Predicting study: RM1S\n",
      "Predicting study: uXdB\n",
      "Predicting study: ipxV\n",
      "Predicting study: AsLD\n",
      "Predicting study: f8H5\n",
      "Predicting study: Y4FK\n",
      "Predicting study: fT68\n",
      "Predicting study: ddTG\n",
      "Predicting study: QDsa\n",
      "Predicting study: Af8a\n",
      "Predicting study: puoa\n"
     ]
    }
   ],
   "source": [
    "train_pred = []\n",
    "train_true = []\n",
    "train_ids = []\n",
    "\n",
    "for fi in splits['train']:\n",
    "    print(f\"Predicting study: {fi}\")\n",
    "    train_ids.append(fi)\n",
    "\n",
    "    sig_file = f\"Matlab/data/{fi}.mat\"\n",
    "    y_file = f\"edf_data/{fi}_new.mat\"\n",
    "    study = MalafeevStudy(signal_file=sig_file, target_file=y_file)\n",
    "\n",
    "    study_prob, study_y = predict_study(model, study)\n",
    "    train_pred.append(np.argmax(study_prob, axis=1))\n",
    "    train_true.append(study_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sindri\\anaconda3\\envs\\u-sleep\\lib\\site-packages\\scipy\\io\\matlab\\_mio5.py:493: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  narr = np.asanyarray(source)\n"
     ]
    }
   ],
   "source": [
    "out = {\"id\": train_ids,\n",
    "    \"yHat\": train_pred,\n",
    "    \"yTrue\": train_true}\n",
    "\n",
    "savemat(\"Matlab/training_performance/malafeev42_new.mat\", mdict=out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "u-sleep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b326a74c38f5ca329da353a7a8d4a270f9d7f24d55ac336e460174c1364f5096"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

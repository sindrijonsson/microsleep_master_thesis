{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Malafeev CNN reference method\n",
    "\n",
    "Malafeev, A., Hertig-Godeschalk, A., Schreier, D. R., Skorucak, J., Mathis, J., & Achermann, P. (2021). Automatic Detection of Microsleep Episodes With Deep Learning. Frontiers in Neuroscience, 15, 564098. https://doi.org/10.3389/fnins.2021.564098\n",
    "\n",
    "This is a reference method with slightly modified implemenations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3200, 1, 3)]      0         \n",
      "                                                                 \n",
      " model (Functional)          (None, 256)               1270528   \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               65792     \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,338,882\n",
      "Trainable params: 1,333,570\n",
      "Non-trainable params: 5,312\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build 16-CNN Model\n",
    "\n",
    "import os\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.callbacks import History \n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Layer,Dense, Dropout, Input, Activation, TimeDistributed, Reshape\n",
    "from keras.layers import  GRU, Bidirectional\n",
    "from keras.layers import  Conv1D, Conv2D, MaxPooling2D, Flatten, BatchNormalization, LSTM, ZeroPadding2D, GlobalAveragePooling2D, SpatialDropout2D\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "def build_model(data_dim, n_channels, n_cl):\n",
    "\teeg_channels = 1\n",
    "\tact_conv = 'relu'\n",
    "\tinit_conv = 'glorot_normal'\n",
    "\tdp_conv = 0.3\n",
    "\tdef cnn_block(input_shape):\n",
    "\t\tinput = Input(shape=input_shape)\n",
    "\t\tx = GaussianNoise(0.0005)(input)\n",
    "\t\tx = Conv2D(32, (3, 1), strides=(1, 1), padding='same', kernel_initializer=init_conv)(x)\n",
    "\t\tx = BatchNormalization()(x)\n",
    "\t\tx = Activation(act_conv)(x)\n",
    "\t\tx = MaxPooling2D(pool_size=(2, 1), padding='same')(x)\n",
    "\t\t\n",
    "\t\t\n",
    "\t\tx = Conv2D(64, (3, 1), strides=(1, 1), padding='same', kernel_initializer=init_conv)(x)\n",
    "\t\tx = BatchNormalization()(x)\n",
    "\t\tx = Activation(act_conv)(x)\n",
    "\t\tx = MaxPooling2D(pool_size=(2, 1), padding='same')(x)\n",
    "\t\tfor i in range(4):\n",
    "\t\t\tx = Conv2D(128, (3, 1), strides=(1, 1), padding='same', kernel_initializer=init_conv)(x)\n",
    "\t\t\tx = BatchNormalization()(x)\n",
    "\t\t\tx = Activation(act_conv)(x)\n",
    "\t\t\tx = MaxPooling2D(pool_size=(2, 1), padding='same')(x)\n",
    "\t\tfor i in range(6):\n",
    "\t\t\tx = Conv2D(256, (3, 1), strides=(1, 1), padding='same', kernel_initializer=init_conv)(x)\n",
    "\t\t\tx = BatchNormalization()(x)\n",
    "\t\t\tx = Activation(act_conv)(x)\n",
    "\t\t\tx = MaxPooling2D(pool_size=(2, 1), padding='same')(x)\n",
    "\t\tflatten1 = Flatten()(x)\n",
    "\t\tcnn_eeg = Model(inputs=input, outputs=flatten1)\n",
    "\t\treturn cnn_eeg\n",
    "\t\t\n",
    "\thidden_units1  = 256\n",
    "\tdp_dense = 0.5\n",
    "\n",
    "\teeg_channels = 1\n",
    "\teog_channels = 2\n",
    "\n",
    "\tinput_eeg = Input(shape=( data_dim, 1,  3))\n",
    "\tcnn_eeg = cnn_block(( data_dim, 1, 3))\n",
    "\tx_eeg = cnn_eeg(input_eeg)\n",
    "\tx = BatchNormalization()(x_eeg)\n",
    "\tx = Dropout(dp_dense)(x)\n",
    "\tx =  Dense(units=hidden_units1, activation=act_conv, kernel_initializer=init_conv)(x)\n",
    "\tx = BatchNormalization()(x)\n",
    "\tx = Dropout(dp_dense)(x)\n",
    "\n",
    "\tpredictions = Dense(units=n_cl, activation='softmax', kernel_initializer=init_conv)(x)\n",
    "\n",
    "\tmodel = Model(inputs=[input_eeg] , outputs=[predictions])\n",
    "\treturn [cnn_eeg, model]\n",
    "\n",
    "cnn, model = build_model(3200, 3, 2)\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load some random subjects from train splits\n",
    "with open(\"./splits/skorucack_splits.json\") as f:\n",
    "    splits = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "class MalafeevStudy(object):\n",
    "\n",
    "    fs = 200\n",
    "    win_len = int(16 * fs)\n",
    "    pad_len = int(win_len / 2)\n",
    "\n",
    "    def __init__(self, signal_file, target_file):\n",
    "        \n",
    "        tmp = loadmat(signal_file, struct_as_record=False, squeeze_me=True)\n",
    "        \n",
    "        pre_process = lambda x: np.clip(x / 100, -1, 1)\n",
    "        padding = lambda x: np.pad(x, pad_width=(self.pad_len, self.pad_len), mode=\"constant\", constant_values = (0, 0))\n",
    "\n",
    "        self.E1 = np.expand_dims(padding(pre_process(tmp['Data'].E1)),-1)\n",
    "        self.E2 = np.expand_dims(padding(pre_process(tmp['Data'].E2)), -1)\n",
    "        O1 = np.expand_dims(padding(pre_process(tmp['Data'].eeg_O1)), -1)\n",
    "        O2 = np.expand_dims(padding(pre_process(tmp['Data'].eeg_O2)), -1)\n",
    "        self.EEG = [O1, O2]\n",
    "\n",
    "        targets = loadmat(target_file)['x']\n",
    "        targets[targets!=1] = 0\n",
    "        self.y = to_categorical(targets, num_classes=2) \n",
    "\n",
    "        self.num_win = len(self.y)\n",
    "\n",
    "\n",
    "    def get_window_by_idx(self, i, c):\n",
    "        \n",
    "        \n",
    "        start = int(i*self.fs)\n",
    "        end = int(start+self.win_len)\n",
    "\n",
    "        x = np.concatenate([self.E1[start:end], self.E2[start:end], self.EEG[c][start:end]],axis=1)\n",
    "        x = np.expand_dims(x, -2)\n",
    "\n",
    "        y = self.y[i]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def get_sample_idx(self, study_idx):\n",
    "\n",
    "        sample_idx = np.empty([self.num_win * 2, 3], dtype=int)\n",
    "        for c in range(2):\n",
    "            for i in range(self.num_win):\n",
    "                ix=int(c*self.num_win+i)\n",
    "                sample_idx[ix,...]=(study_idx, i, c)\n",
    "        return sample_idx  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "class Generator(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, split, batch_size):\n",
    "        self.studies = [MalafeevStudy(signal_file=f\"Matlab/data/{f}\", target_file=f\"edf_data/{f.replace('.mat','_status.mat')}\") for f in split]\n",
    "        self.indices = flatten([tmp.get_sample_idx(i) for i, tmp in enumerate(self.studies)])\n",
    "        self.batch_size = batch_size\n",
    "        np.random.shuffle(self.indices)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.indices) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        batch_x = np.empty([self.batch_size, self.studies[0].win_len, 1, 3])\n",
    "        batch_y = np.empty([self.batch_size, 2])\n",
    "\n",
    "        idxs = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        for i, idx in enumerate(idxs):\n",
    "            x, y = self.get_study_windows_by_idx(idx)\n",
    "            batch_x[i,...] = x\n",
    "            batch_y[i,...] = y\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def get_study_windows_by_idx(self, index):\n",
    "\n",
    "        return self.studies[index[0]].get_window_by_idx(index[1], index[2])\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.indices)\n",
    "\n",
    "train_data = Generator(split=splits['train'], batch_size=200)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend\n",
    "\n",
    "fs = 200\n",
    "win_sec = 16\n",
    "win_len = win_sec * fs\n",
    "n_classes = 2\n",
    "n_channels = 3\n",
    "\n",
    "\n",
    "_, model = build_model(win_len, n_channels, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "# Compute class weights\n",
    "y = flatten([x.y[...,1] for x in train_data.studies])\n",
    "cls = np.arange(n_classes)\n",
    "clw = compute_class_weight(class_weight=\"balanced\", classes=cls, y=y)\n",
    "class_weights = {0: clw[0], 1: clw[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "train_model = False\n",
    "folder = \"malafeev42\"\n",
    "weight_file = os.path.join(folder,\"CNN_weights.h5\")\n",
    "history_file = os.path.join(folder, \"history\")\n",
    "\n",
    "\n",
    "\n",
    "if train_model:\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Nadam(learning_rate=0.002),\n",
    "                loss=keras.losses.CategoricalCrossentropy(),\n",
    "                metrics=keras.metrics.CategoricalAccuracy())\n",
    "\n",
    "\n",
    "    with tf.device(\"/device:GPU:0\"):\n",
    "        history = model.fit(train_data, \n",
    "                            class_weight=class_weights,\n",
    "                            epochs=3)\n",
    "    \n",
    "    import pickle\n",
    "    model.save_weights(\"CNN_weights.h5\")\n",
    "\n",
    "    with open('history', 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)\n",
    "\n",
    "else:\n",
    "    model.load_weights(f\"{folder}\\\\CNN_weights.h5\")\n",
    "\n",
    "    with open(history_file, 'rb') as file_pi:\n",
    "        history = pickle.load(file_pi)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_study(mdl, study: MalafeevStudy):\n",
    "\n",
    "    n_classes = mdl.output_shape[-1]\n",
    "    n_channels = mdl.input_shape[-1]\n",
    "\n",
    "    ch_x = np.empty([study.num_win, study.win_len, 1, n_channels])\n",
    "    ch_y = np.empty([study.num_win])\n",
    "    study_preds = np.empty([study.num_win, n_classes, n_channels])\n",
    "\n",
    "    idxs = study.get_sample_idx(0)\n",
    "\n",
    "    for ch in range(n_channels):\n",
    "        \n",
    "        ch_idx = idxs[np.where(idxs[:,2]==ch)[0],1:3]\n",
    "        \n",
    "        for i, idx in enumerate(ch_idx):\n",
    "            x, y = study.get_window_by_idx(*idx)\n",
    "            ch_x[i,...] = x\n",
    "            ch_y[i,...] = y[-1]\n",
    "\n",
    "        study_preds[...,ch] = mdl.predict_on_batch(ch_x)\n",
    "\n",
    "    return np.mean(study_preds, axis=2), ch_y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting study: 0pai\n",
      "Predicting study: 6JVj\n",
      "Predicting study: 40kO\n",
      "Predicting study: DSfb\n",
      "Predicting study: EyTS\n",
      "Predicting study: hcml\n",
      "Predicting study: hRMy\n",
      "Predicting study: Kn9O\n",
      "Predicting study: mBks\n",
      "Predicting study: mZje\n",
      "Predicting study: R2f3\n",
      "Predicting study: Xii6\n",
      "Predicting study: kj2l\n",
      "Predicting study: 3P0D\n",
      "Predicting study: 6iwd\n",
      "Predicting study: BSvO\n",
      "Predicting study: csxQ\n",
      "Predicting study: ibbz\n",
      "Predicting study: IhpU\n",
      "Predicting study: N1nM\n",
      "Predicting study: Otq3\n",
      "Predicting study: tG6i\n",
      "Predicting study: Xg1l\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "ids = []\n",
    "\n",
    "for fi in splits['test']:\n",
    "    print(f\"Predicting study: {fi}\")\n",
    "    ids.append(fi)\n",
    "\n",
    "    sig_file = f\"Matlab/data/{fi}.mat\"\n",
    "    y_file = f\"edf_data/{fi}_status.mat\"\n",
    "    study = MalafeevStudy(signal_file=sig_file, target_file=y_file)\n",
    "\n",
    "    study_prob, study_y = predict_study(model, study)\n",
    "    y_pred.append(np.argmax(study_prob, axis=1))\n",
    "    y_true.append(study_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:\t\t0.63\n",
      "Precision:\t0.88\n",
      "F1-Score:\t0.73\n",
      "Cohen's kappa:\t0.71\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score, cohen_kappa_score, confusion_matrix\n",
    "\n",
    "y_true=[(y==1)*1 for y in y_true]\n",
    "y_hat = np.concatenate(y_pred)\n",
    "y = np.concatenate(y_true)==1\n",
    "\n",
    "recall = recall_score(y, y_hat)\n",
    "precision = precision_score(y, y_hat)\n",
    "f1 = f1_score(y, y_hat)\n",
    "kappa = cohen_kappa_score(y, y_hat)\n",
    "\n",
    "print(f\"Recall:\\t\\t{recall:.2f}\")\n",
    "print(f\"Precision:\\t{precision:.2f}\")\n",
    "print(f\"F1-Score:\\t{f1:.2f}\")\n",
    "print(f\"Cohen's kappa:\\t{kappa:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sindri\\anaconda3\\envs\\u-sleep\\lib\\site-packages\\scipy\\io\\matlab\\_mio5.py:493: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  narr = np.asanyarray(source)\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import savemat\n",
    "\n",
    "ids = splits['test']\n",
    "out = {\"id\": ids,\n",
    "    \"yHat\": y_pred,\n",
    "    \"yTrue\": y_true}\n",
    "\n",
    "savemat(\"Matlab/malafeev42.mat\", mdict=out)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate train data to check overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting study: AXbm\n",
      "Predicting study: hT38\n",
      "Predicting study: Msy4\n",
      "Predicting study: pPpj\n",
      "Predicting study: go56\n",
      "Predicting study: SOZ3\n",
      "Predicting study: X7s0\n",
      "Predicting study: muls\n",
      "Predicting study: 5bSg\n",
      "Predicting study: Nzhl\n",
      "Predicting study: C1Wu\n",
      "Predicting study: cblr\n",
      "Predicting study: svlu\n",
      "Predicting study: YHLr\n",
      "Predicting study: EHED\n",
      "Predicting study: G7PJ\n",
      "Predicting study: DYYI\n",
      "Predicting study: RfL0\n",
      "Predicting study: ZYFG\n",
      "Predicting study: 0ncr\n",
      "Predicting study: iSqw\n",
      "Predicting study: Dr51\n",
      "Predicting study: UwK6\n",
      "Predicting study: Ivfn\n",
      "Predicting study: LR2s\n",
      "Predicting study: Zpwh\n",
      "Predicting study: DjrT\n",
      "Predicting study: bkx9\n",
      "Predicting study: MS6u\n",
      "Predicting study: fNe4\n",
      "Predicting study: 9098\n",
      "Predicting study: EMcQ\n",
      "Predicting study: YOh8\n",
      "Predicting study: UsSz\n",
      "Predicting study: y5We\n",
      "Predicting study: 9JQY\n",
      "Predicting study: zaca\n",
      "Predicting study: 3J4W\n",
      "Predicting study: sNMf\n",
      "Predicting study: d3ET\n",
      "Predicting study: JCpz\n",
      "Predicting study: oOMR\n",
      "Predicting study: RM1S\n",
      "Predicting study: uXdB\n",
      "Predicting study: ipxV\n",
      "Predicting study: AsLD\n",
      "Predicting study: f8H5\n",
      "Predicting study: Y4FK\n",
      "Predicting study: fT68\n",
      "Predicting study: ddTG\n",
      "Predicting study: QDsa\n",
      "Predicting study: Af8a\n",
      "Predicting study: puoa\n"
     ]
    }
   ],
   "source": [
    "train_pred = []\n",
    "train_true = []\n",
    "train_ids = []\n",
    "\n",
    "for fi in splits['train']:\n",
    "    print(f\"Predicting study: {fi}\")\n",
    "    train_ids.append(fi)\n",
    "\n",
    "    sig_file = f\"Matlab/data/{fi}.mat\"\n",
    "    y_file = f\"edf_data/{fi}_status.mat\"\n",
    "    study = MalafeevStudy(signal_file=sig_file, target_file=y_file)\n",
    "\n",
    "    study_prob, study_y = predict_study(model, study)\n",
    "    train_pred.append(np.argmax(study_prob, axis=1))\n",
    "    train_true.append(study_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sindri\\anaconda3\\envs\\u-sleep\\lib\\site-packages\\scipy\\io\\matlab\\_mio5.py:493: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  narr = np.asanyarray(source)\n"
     ]
    }
   ],
   "source": [
    "out = {\"id\": train_ids,\n",
    "    \"yHat\": train_pred,\n",
    "    \"yTrue\": train_true}\n",
    "\n",
    "savemat(\"Matlab/training_performance/malafeev42.mat\", mdict=out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "u-sleep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c8e95707acf1fc7af41c9420274be1f4b282295d5d7ada269f0cddd16fb8c714"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

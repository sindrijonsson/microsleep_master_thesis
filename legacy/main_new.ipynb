{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2e16f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import typing \n",
    "\n",
    "from IPython.display import clear_output\n",
    "from misc import _get_usleep_token\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "from pprint import pprint\n",
    "from scipy import io, special\n",
    "from scipy.stats import mode\n",
    "\n",
    "from sklearn import metrics, model_selection\n",
    "\n",
    "# Import project utils\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e093aa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS \n",
    "\n",
    "MS_MAPPING = {\"Wake\": 0, \"MS\": 1}\n",
    "AASM_MAPPING = {\"Wake\": 0, \"N1\": 1, \"N2\": 2, \"N3\": 3, \"REM\": 4}\n",
    "\n",
    "float_formatter = \"{:.2f}\".format\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c83b77f",
   "metadata": {},
   "source": [
    "## Manuscript for preliminary U-Sleep evaluation on Bern data\n",
    "The comparison will be made with the results from Skorucack et al., 2020 (RF, SVM, LSTM classifiers).\n",
    "The evaluation used in the reference study:\n",
    "- bMSE vs Wake (also some other classification problems e.g. bMSE vs {Wake, uMSE, uMSEc, uED})\n",
    "- True labels were converted from 200 Hz to 5 Hz (200 ms resolution) using a 9 second median filter with 200 ms step size.\n",
    "- Predictions from the RF and SVM were converted to 5 Hz resolution using same median filter.\n",
    "- MS predictions after resampling which were shorter than 1 second were excluded\n",
    "- Calculate sensitivity, specificity, accuracy, precision, cohen's kappa.\n",
    "    \n",
    "In this analysis, we will use the same dev/test split (53/23) and adapt the U-Sleep output to fit the same evaluation scheme as used in the reference paper.\n",
    "The hyperparameters of the U-Sleep model are:\n",
    "* Data per prediction (prediction rate): 1, 2, 4, 8, 16\n",
    "* Post-procesing of probabilities: y_argmax (not w/ tunable threshold), y_max_sleep, and y_sum_sleep\n",
    "* MS Threshold: 0.025:0.025:1.0\n",
    "\n",
    "Therefore, making 5x3 = 15 models.\n",
    "Since the U-Sleep model is pre-trained, the only \"training\" part is the threshold tuning. The optimal threshold will be determined by the highest f1-score analogous to Brink-KjÃ¦r. The optimal model will be found by using a 5-fold CV validation where a model will be trained (tune threshold) on K-1 folds and validated against the remaining fold. The model with the highest f1-score will be chosen and re-trained on the entire dev set before evaluating it on the test set.\n",
    "\n",
    "---\n",
    "## Update (09/10/2020)\n",
    "* Reproduce methods by Skorucak et al., 2020\n",
    "* Comparison between U-Sleep and Bern with their definition\n",
    "* Comparison between U-Sleep and Bern with our duration criteria of microsleep\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b720a51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_probs(rec):\n",
    "    probs = get_probs(rec)\n",
    "    probs_sum = np.column_stack([probs[:,0], np.sum(probs[:,1:5],axis=1)])\n",
    "    probs_max = np.column_stack([probs[:,0], np.max(probs[:,1:5],axis=1)])\n",
    "    \n",
    "    return probs, probs_sum, probs_max\n",
    "\n",
    "\n",
    "def psuedo_resample(y_org, first_last):\n",
    "    if len(y_org.shape) > 1:\n",
    "        return np.array([np.median(y_org[:,x[0]:x[1]],1) for x in first_last]).T\n",
    "    else:\n",
    "        return np.array([np.median(y_org[x[0]:x[1]]) for x in first_last])\n",
    "    \n",
    "make_first_last = lambda time_pos, hz: np.array([[np.floor(x[0]*hz), np.ceil(x[-1]*hz)+1] for x in time_pos], dtype=int)\n",
    "\n",
    "_map = {\"Wake\": [0,2,3], \"MS\": [1]}\n",
    "_uni = False\n",
    "\n",
    "# thresholds\n",
    "# Initialization\n",
    "tstep = 0.025\n",
    "tstart = 0.025\n",
    "tmax = 1.0\n",
    "tnum = ((tmax - tstart) / tstep) + 1\n",
    "thresholds = np.linspace(tstart,1.0,np.round(tnum).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7b2a07ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe creation for 8 Hz\n",
      "Dataframe creation for 16 Hz\n",
      "Dataframe creation for 32 Hz\n",
      "Dataframe creation for 64 Hz\n",
      "Dataframe creation for 128 Hz\n"
     ]
    }
   ],
   "source": [
    "## PROCESSING PRELIM ANALYSIS\n",
    "\n",
    "HZ = [8, 16, 32, 64, 128]\n",
    "for hz in HZ:\n",
    "    resampled_labels = dict.fromkeys(all_names)\n",
    "    resampled_first_last = dict.fromkeys(all_names)\n",
    "    entries = []\n",
    "        \n",
    "    print(f\"Dataframe creation for {hz} Hz\")\n",
    "    for edf, lab in zip(all_edf_files, all_labels_files):\n",
    "\n",
    "        _id = edf.replace(\".edf\",\"\")\n",
    "        _type = \"train\" if _id in splits[\"train\"] else \"test\"\n",
    "\n",
    "        _edf = os.path.join(\"edf_data\",edf)\n",
    "        _labels = os.path.join(\"labels\",lab)\n",
    "        _preds = os.path.join(\"predictions\", f\"{hz}_hz\",f\"{_id}.npy\")\n",
    "\n",
    "        _tmp = BernLabels(lab, _map, _uni)\n",
    "        _any_ms = np.sum(_tmp.labels) > 1\n",
    "\n",
    "        _ms_200, _time_pos = _tmp.apply_rolling_func(win=0.2, step=0.2)\n",
    "        _ms_200[_ms_200 == 0.5] == 1\n",
    "        _any_ms_200 = np.sum(_ms_200) > 1\n",
    "\n",
    "        entry = {\"type\": _type, \"id\": _id, \"edf\": _edf, \"labels\": _labels, \"preds\": _preds,\n",
    "                 \"ms\": _any_ms, \"ms_200\": _any_ms_200}\n",
    "        entries.append(entry)\n",
    "\n",
    "        fixed_resampled_labels = _ms_200\n",
    "        fixed_resampled_labels[fixed_resampled_labels==0.5] == 1\n",
    "        \n",
    "        resampled_labels[_id] = np.array(fixed_resampled_labels, dtype=int)\n",
    "        resampled_first_last[_id] = make_first_last(_time_pos, hz)\n",
    "\n",
    "    df = pd.DataFrame.from_records(entries)\n",
    "    df.to_csv(f\"prelim_data/corrected_{hz}_info_df.csv\")\n",
    "\n",
    "#     processed_recs = dict.fromkeys(all_names)\n",
    "#     print(f\"Processing recs for {hz} Hz\")\n",
    "    \n",
    "#     for i, row in df.iterrows():\n",
    "#         print(f\"{i+1}/{df.shape[0]}\")\n",
    "#         p1,p2,p3 = get_all_probs(row.preds)\n",
    "#         fl = resampled_first_last[row.id]\n",
    "\n",
    "#         # Argmax\n",
    "#         preds_argmax = aasm_to_wake_sleep(np.argmax(p1,axis=1))\n",
    "#         resampled_preds_argmax=psuedo_resample(preds_argmax, fl)\n",
    "#         resampled_preds_argmax[resampled_preds_argmax==0.5] = 1\n",
    "        \n",
    "#         # Sum\n",
    "#         preds_sum = np.array([p2[:,1] > t for t in thresholds])*1\n",
    "#         resampled_preds_sum=psuedo_resample(preds_sum, fl)\n",
    "#         resampled_preds_sum[resampled_preds_sum==0.5] = 1\n",
    "        \n",
    "#         # Max\n",
    "#         preds_max = np.array([p3[:,1] > t for t in thresholds])*1\n",
    "#         resampled_preds_max=psuedo_resample(preds_max, fl)\n",
    "#         resampled_preds_max[resampled_preds_max==0.5] = 1\n",
    "            \n",
    "#         # Store\n",
    "#         entry = {\"preds_argmax\": resampled_preds_argmax,\n",
    "#                  \"preds_sum\": resampled_preds_sum,\n",
    "#                  \"preds_max\": resampled_preds_max,\n",
    "#                  \"labels\": resampled_labels[row.id]}\n",
    "#         processed_recs[row.id] = entry\n",
    "#         clear_output(wait=True)\n",
    "\n",
    "\n",
    "#     pickle_file = f'{hz}_processed_recs2.pickle'\n",
    "#     write_to_pickle_file(processed_recs, pickle_file)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af1221b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_df = pd.read_csv(\"prelim_data/corrected_8_info_df.csv\")\n",
    "test_df = _df[_df.type==\"test\"].reset_index(drop=True)\n",
    "dev_df = _df[_df.type==\"train\"].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "93ac5b22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 4 - Hz: 8 - Method: preds_max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sindri\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\sindri\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\sindri\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "seed = 42\n",
    "k = 5\n",
    "skf = model_selection.StratifiedKFold(k, shuffle=True, random_state=seed)\n",
    "\n",
    "pred_keys = [\"preds_argmax\",\"preds_sum\",\"preds_max\"]\n",
    "HZ = [128, 64, 32, 16, 8]\n",
    "i = 0\n",
    "for hz in HZ:\n",
    "    processed_recs_file = f\"prelim_data/{hz}_processed_recs2.pickle\"\n",
    "    processed_recs = load_pickle_from_file(processed_recs_file)\n",
    "    for pk in pred_keys:\n",
    "        for k, (train_idx, val_idx) in enumerate(skf.split(dev_df.index, dev_df.ms)):   \n",
    "\n",
    "            print(f\"K: {k} - Hz: {hz} - Method: {pk}\")\n",
    "            train_id = dev_df.id[train_idx].values\n",
    "            val_id = dev_df.id[val_idx].values\n",
    "            \n",
    "            train_yhat, train_y = my_collector(collection = processed_recs, ids = train_id, key=pk, rm = True)\n",
    "            val_yhat, val_y     = my_collector(collection = processed_recs, ids = val_id, key=pk, rm = True)\n",
    "\n",
    "            k_tracker = Tracker(k, train_y, train_yhat, val_y, val_yhat)\n",
    "            k_dict = k_tracker.to_dict()\n",
    "            k_dict[\"method\"] = pk\n",
    "            k_dict[\"hz\"] = hz\n",
    "\n",
    "            if i == 0:\n",
    "                k_df = pd.DataFrame(k_dict, index=[i])\n",
    "            else:\n",
    "                k_df = pd.concat([k_df, pd.DataFrame(k_dict, index=[i])])\n",
    "\n",
    "            clear_output(wait=True)\n",
    "            i += 1\n",
    "        k_df.to_csv(\"corrected_prelim2_df.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
